{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\nur.yilmaz\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\nur.yilmaz\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\nur.yilmaz\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\nur.yilmaz\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\nur.yilmaz\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\nur.yilmaz\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\nur.yilmaz\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\nur.yilmaz\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\nur.yilmaz\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\nur.yilmaz\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\nur.yilmaz\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\nur.yilmaz\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = os.getcwd() + '\\\\Train_data_resized\\\\'\n",
    "X = []\n",
    "y = []\n",
    "for image_path in os.listdir(os.fsencode(image_dir)):\n",
    "    for image in os.listdir(os.fsencode(image_dir + str(image_path).replace(\"b'\", '').replace(\"'\", ''))):\n",
    "        img_dir = os.fsencode(image_dir + str(image_path).replace(\"b'\", '').replace(\"'\", '') + '\\\\' + str(image).replace(\"b'\", '').replace(\"'\", ''))\n",
    "        img = Image.open(img_dir)\n",
    "        if img.size == (128,128):\n",
    "            I = np.array(img.getdata(),\n",
    "                        np.uint8).reshape(49152 , 1)\n",
    "\n",
    "            X.append(I.reshape(1 , 49152))\n",
    "            y.append(str(image_path).replace(\"b'\", '').replace(\"'\", ''))\n",
    "        \n",
    "        else:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(X).shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.image_data_format() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    " X = np.array(X).reshape(np.array(X).shape[0], 3, 128, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"if K.image_data_format() == 'channels_last':\n",
    "        X = np.array(X).reshape(np.array(X).shape[0], 3, 128, 128)\n",
    "        input_shape = (3, 128, 128)\n",
    "else:\n",
    "        X = np.array(X).reshape(np.array(X).shape[0], 128, 128, 3)\n",
    "        input_shape = (128, 128, 3)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = LabelEncoder()\n",
    "\n",
    "y = lb.fit_transform(y)\n",
    "y = keras.utils.to_categorical(y,6) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\nur.yilmaz\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nur.yilmaz\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(3, 3), data_format=\"channels_first\")`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "model.add(Conv2D(64, (3, 3), padding='same',\n",
    "                 input_shape=X_train.shape[1:]))\n",
    "# add relu activation function\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dropout(0.3))\n",
    "# add layer with 3x3 filters to model\n",
    "model.add(MaxPooling2D(pool_size=(3, 3), dim_ordering=\"th\"))\n",
    "# randomly close 0.10 of neurons to prevent overfitting during training\n",
    "model.add(Dropout(0.10))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(32, (3, 3), data_format='channels_first'))\n",
    "# add relu activation function\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dropout(0.3))\n",
    "# add 2x2 MaxPooling layer \n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# randomly close 0.10 of neurons to prevent overfitting during training\n",
    "model.add(Dropout(0.10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert 2D images to 1D vector\n",
    "model.add(Flatten())\n",
    "# add to model 512 neurons\n",
    "model.add(Dense(256))\n",
    "# add relu activation function\n",
    "model.add(Activation('relu'))\n",
    "# randomly close 0.30 of neurons\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(6)) # num_classes = 6\n",
    "#add \"Softmax\" function to calculate the probability of classes\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = keras.optimizers.adam(lr=0.01, decay=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_monitor = EarlyStopping(patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\nur.yilmaz\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Users\\nur.yilmaz\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 56 samples, validate on 15 samples\n",
      "Epoch 1/15\n",
      "56/56 [==============================] - 1s 19ms/step - loss: 0.6041 - accuracy: 0.7857 - val_loss: 0.7584 - val_accuracy: 0.7556\n",
      "Epoch 2/15\n",
      "56/56 [==============================] - 0s 8ms/step - loss: 1.4045 - accuracy: 0.7738 - val_loss: 1.1951 - val_accuracy: 0.8222\n",
      "Epoch 3/15\n",
      "56/56 [==============================] - 0s 7ms/step - loss: 2.6941 - accuracy: 0.7917 - val_loss: 0.6869 - val_accuracy: 0.8222\n",
      "Epoch 4/15\n",
      "56/56 [==============================] - 0s 7ms/step - loss: 1.6759 - accuracy: 0.7917 - val_loss: 0.3847 - val_accuracy: 0.8333\n",
      "Epoch 5/15\n",
      "56/56 [==============================] - 0s 7ms/step - loss: 0.5910 - accuracy: 0.7857 - val_loss: 0.4299 - val_accuracy: 0.8333\n",
      "Epoch 6/15\n",
      "56/56 [==============================] - 0s 7ms/step - loss: 0.4550 - accuracy: 0.8333 - val_loss: 0.4473 - val_accuracy: 0.8333\n",
      "Epoch 7/15\n",
      "56/56 [==============================] - 0s 7ms/step - loss: 0.4575 - accuracy: 0.8333 - val_loss: 0.4511 - val_accuracy: 0.8333\n",
      "Epoch 8/15\n",
      "56/56 [==============================] - 0s 7ms/step - loss: 0.4610 - accuracy: 0.8333 - val_loss: 0.4501 - val_accuracy: 0.8333\n",
      "Epoch 9/15\n",
      "56/56 [==============================] - 0s 8ms/step - loss: 0.4543 - accuracy: 0.8333 - val_loss: 0.4489 - val_accuracy: 0.8333\n",
      "Epoch 10/15\n",
      "56/56 [==============================] - 0s 8ms/step - loss: 0.4498 - accuracy: 0.8333 - val_loss: 0.4473 - val_accuracy: 0.8333\n",
      "Epoch 11/15\n",
      "56/56 [==============================] - 1s 9ms/step - loss: 0.4467 - accuracy: 0.8333 - val_loss: 0.4445 - val_accuracy: 0.8333\n",
      "Epoch 12/15\n",
      "56/56 [==============================] - 0s 8ms/step - loss: 0.4421 - accuracy: 0.8333 - val_loss: 0.4395 - val_accuracy: 0.8333\n",
      "Epoch 13/15\n",
      "56/56 [==============================] - 0s 9ms/step - loss: 0.4361 - accuracy: 0.8333 - val_loss: 0.4322 - val_accuracy: 0.8333\n",
      "Epoch 14/15\n",
      "56/56 [==============================] - 0s 8ms/step - loss: 0.4328 - accuracy: 0.8333 - val_loss: 0.4258 - val_accuracy: 0.8333\n",
      "Epoch 15/15\n",
      "56/56 [==============================] - 0s 8ms/step - loss: 0.4249 - accuracy: 0.8333 - val_loss: 0.4190 - val_accuracy: 0.8333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x2435e8cc5c0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train,\n",
    "              batch_size=128,\n",
    "              epochs=15,\n",
    "              validation_data=(X_test, y_test),\n",
    "              verbose=1,\n",
    "              shuffle=True,\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 3ms/step\n",
      "Test loss: 0.41899335384368896\n",
      "Test accuracy: 0.8333333134651184\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X_test, y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from PIL import ImageOps\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "img_dir = glob.glob('C://Users//**//Desktop//**//ImageCrawler - Deploy//Test_Data//*')\n",
    "  \n",
    "for file in img_dir :\n",
    "    for image_dir in glob.glob(file + \"//*\"): \n",
    "        \n",
    "        img = Image.open(image_dir)\n",
    "        new_path = image_dir.replace('Test_Data', 'Test_Data_resized').replace('\\\\', '//')\n",
    "        \n",
    "        # Create each image from related directory via Image\n",
    "        \n",
    "        # Convert to RGB\n",
    "        img = img.convert('RGB')\n",
    "        # Resize image to the biggest dimension by making aspect ratio 1:1\n",
    "        old_size = img.size\n",
    "        max_size =  np.max(list(old_size))\n",
    "        new_size = (max_size, max_size)\n",
    "        # Create a canvas with white background, insert considered image to its center\n",
    "        new_im = Image.new(\"RGB\", new_size, 'white')\n",
    "        new_im.paste(img, (int((new_size[0]-old_size[0])/2),\n",
    "                      int((new_size[1]-old_size[1])/2)))\n",
    "        # Autocontrast the image.\n",
    "        auto_img = ImageOps.autocontrast(new_im)\n",
    "        auto_img.thumbnail((128, 128))\n",
    "        \n",
    "        # Save the image to new path.\n",
    "        auto_img.save(new_path)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import flask\n",
    "\n",
    "import keras.models\n",
    "\n",
    "from werkzeug.wrappers import Request, Response\n",
    "from flask import Flask\n",
    "from flask import request\n",
    "\n",
    "from keras.applications.imagenet_utils import decode_predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/handle_request', methods=['GET', 'POST'])\n",
    "def handle_request():\n",
    "    \n",
    "    \n",
    "    img = request.args.get('path')\n",
    "    \n",
    "    img = Image.open(img)\n",
    "    loaded_model = keras.models.load_model('model.h5')\n",
    "    A = []\n",
    "    \n",
    "    I = np.array(img.getdata(),\n",
    "                np.uint8).reshape(49152 , 1)\n",
    "    A.append(I.reshape(1 , 49152))\n",
    "\n",
    "    A = np.array(A).reshape(np.array(A).shape[0], 3, 128, 128)\n",
    "    A = A/255\n",
    "\n",
    "    preds = loaded_model.predict(A)\n",
    "    \n",
    "     \n",
    "    y_classes = preds.argmax(axis=-1)\n",
    "    \n",
    "   \n",
    "    \n",
    "    return str(lb.inverse_transform(y_classes[0]))\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://localhost:9000/ (Press CTRL+C to quit)\n",
      "C:\\Users\\nur.yilmaz\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "127.0.0.1 - - [15/Oct/2019 14:15:35] \"\u001b[37mGET /handle_request?path=C:\\389725.jpg HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    from werkzeug.serving import run_simple\n",
    "    run_simple('localhost', 9000, app)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
